{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70cb06b4-f58d-46e0-8f71-b616bcc0512d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Group HOMEWORK**. This final project can be collaborative. The maximum members of a group is 2. You can also work by yourself. Please respect the academic integrity. **Remember: if you get caught on cheating, you get F.**\n",
    "\n",
    "## A Introduction to the competition\n",
    "\n",
    "<img src=\"news-sexisme-EN.jpg\" alt=\"drawing\" width=\"380\"/>\n",
    "\n",
    "Sexism is a growing problem online. It can inflict harm on women who are targeted, make online spaces inaccessible and unwelcoming, and perpetuate social asymmetries and injustices. Automated tools are now widely deployed to find, and assess sexist content at scale but most only give classifications for generic, high-level categories, with no further explanation. Flagging what is sexist content and also explaining why it is sexist improves interpretability, trust and understanding of the decisions that automated tools use, empowering both users and moderators.\n",
    "\n",
    "This project is based on SemEval 2023 - Task 10 - Explainable Detection of Online Sexism (EDOS). [Here](https://codalab.lisn.upsaclay.fr/competitions/7124#learn_the_details-overview) you can find a detailed introduction to this task.\n",
    "\n",
    "You only need to complete **TASK A - Binary Sexism Detection: a two-class (or binary) classification where systems have to predict whether a post is sexist or not sexist**. To cut down training time, we only use a subset of the original dataset (5k out of 20k). The dataset can be found in the same folder. \n",
    "\n",
    "Different from our previous homework, this competition gives you great flexibility (and very few hints), you can determine: \n",
    "-  how to preprocess the input text (e.g., remove emoji, remove stopwords, text lemmatization and stemming, etc.);\n",
    "-  which method to use to encode text features (e.g., TF-IDF, N-grams, Word2vec, GloVe, Part-of-Speech (POS), etc.);\n",
    "-  which model to use.\n",
    "\n",
    "## Requirements\n",
    "-  **Input**: the text for each instance.\n",
    "-  **Output**: the binary label for each instance.\n",
    "-  **Feature engineering**: use at least 2 different methods to extract features and encode text into numerical values.\n",
    "-  **Model selection**: implement with at least 3 different models and compare their performance.\n",
    "-  **Evaluation**: create a dataframe with rows indicating feature+model and columns indicating Precision, Accuracy and F1-score (using weighted average). Your results should have at least 6 rows (2 feature engineering methods x 3 models). Report best performance with (1) your feature engineering method, and (2) the model you choose. \n",
    "- **Format**: add explainations for each step (you can add markdown cells). At the end of the report, write a summary and answer the following questions: \n",
    "    - What preprocessing steps do you follow?\n",
    "    - How do you select the features from the inputs? \n",
    "    - Which model you use and what is the structure of your model?\n",
    "    - How do you train your model?\n",
    "    - What is the performance of your best model?\n",
    "    - What other models or feature engineering methods would you like to implement in the future?\n",
    "- **Two Rules**, violations will result in 0 points in the grade: \n",
    "    - Not allowed to use test set in the training: You CANNOT use any of the instances from test set in the training process. \n",
    "    - Not allowed to use code from generative AI (e.g., ChatGPT). \n",
    "\n",
    "## Evaluation\n",
    "\n",
    "The performance should be only evaluated on the test set (a total of 1086 instances). Please split original dataset into train set and test set. The test set should NEVER be used in the training process. The evaluation metric is a combination of precision, recall, and f1-score (use `classification_report` in sklearn). \n",
    "\n",
    "The total points are 10.0. Each team will compete with other teams in the class on their best performance. Points will be deducted if not following the requirements above.\n",
    "\n",
    "If ALL the requirements are met:\n",
    "- Top 25\\% teams: 10.0 points.\n",
    "- Top 25\\% - 50\\% teams: 8.5 points.\n",
    "- Top 50\\% - 75\\% teams: 7.0 points.\n",
    "- Top 75\\% - 100\\% teams: 6.0 points.\n",
    "\n",
    "## Submission\n",
    "Similar as homework, submit both a PDF and .ipynb version of the report. \n",
    "\n",
    "The report should include: (a)code, (b)outputs, (c)explainations for each step, and (d)summary (you can add markdown cells). \n",
    "\n",
    "The due date is **December 8, Friday by 11:59pm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b7caf28-1c77-4f87-8a62-7f3a7f79e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything we need\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f516ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the test and train dataframes, and spilling into X(text) and Y(label)\n",
    "comments_df = pd.read_csv('edos_labelled_data.csv') \n",
    "le = preprocessing.LabelEncoder()\n",
    "comments_df[\"label\"] = le.fit_transform(comments_df[\"label\"])\n",
    "comments_train_df = comments_df[comments_df[\"split\"] == \"train\"]\n",
    "comments_test_df = comments_df[comments_df[\"split\"] == \"test\"]\n",
    "X_train = comments_train_df[\"text\"]\n",
    "Y_train = comments_train_df[\"label\"]\n",
    "X_test = comments_test_df[\"text\"]\n",
    "Y_test = comments_test_df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fde145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(comments: list[str]) -> list[str]:\n",
    "    # Removes unicode characters and punctuation and makes everything lowercase\n",
    "    # Returns a list of \"cleaned\" strings\n",
    "    wln = WordNetLemmatizer()\n",
    "    comments_clean = [comment.encode(\"ascii\", \"ignore\").decode() for comment in comments]\n",
    "    comments_clean = list(map(lambda x : x.lower(), comments_clean))\n",
    "    comments_clean = [re.sub(r'(#\\w+|\\[user\\]|\\[url\\])', '', comment) for comment in comments_clean]\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    comments_clean = [comment.translate(translator) for comment in comments_clean]\n",
    "\n",
    "    return comments_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc398840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def clean2EvenCleaner(x):\n",
    "    clean_x = clean(x)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    out = []\n",
    "    for sentence in clean_x:\n",
    "        tokens = pos_tag(word_tokenize(sentence))\n",
    "        tagged = list(map(\n",
    "                lambda x : (x[0], get_wordnet_pos(x[1])),\n",
    "                tokens\n",
    "        ))\n",
    "        \n",
    "        word_and_pos = list(filter(\n",
    "            lambda x : x[1] != '', \n",
    "            tagged\n",
    "        ))\n",
    "\n",
    "        out.append(\" \".join(list(map(lambda x : lemmatizer.lemmatize(x[0], x[1]), word_and_pos))))\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a23c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toWordFreqDF(x, y):\n",
    "    clean_x = clean(x)\n",
    "    vectorizer = CountVectorizer()\n",
    "    vec = vectorizer.fit_transform(clean_x)\n",
    "    frequency_df = pd.DataFrame(vec.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    frequency_df['_label'] = y.tolist()\n",
    "    frequency_df['_label'].tail()\n",
    "    return frequency_df\n",
    "\n",
    "train_freq = toWordFreqDF(X_train, Y_train)\n",
    "test_freq = toWordFreqDF(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e23240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sexist_comment_percent = the percentage of comments that are sexist (as a decimal)\n",
    "sexist_comment_percent = len(Y_train.loc[Y_train== 1]) / len(Y_train)\n",
    "# common_freq = all words that appear at least 5 times\n",
    "common_freq = train_freq.sum().loc[train_freq.sum() >= 5]\n",
    "# sexist = the number of times a word appears in a sexist comment given for all words in common_freq\n",
    "sexist = train_freq[train_freq[\"_label\"] == 1].sum().loc[train_freq.sum() >= 5]\n",
    "# ratio = # of sexist comments / # of comments for all words in common_freq\n",
    "ratio  = (sexist/common_freq).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1820237c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-8, 0.7872235271864106)\n",
      "(-3, 0.7889672885458582)\n",
      "0.7685862242158681\n"
     ]
    }
   ],
   "source": [
    "# The first model checks if a comment contains a word in the bad_words list\n",
    "# If it does, the comments is decided to be sexist, if not the comment is decided to be non-sexist\n",
    "def model_1(sentence : str, bad_words):\n",
    "    for word in sentence.split():\n",
    "        if word in bad_words:\n",
    "            return 1  \n",
    "    return 0\n",
    "\n",
    "\n",
    "# Find the best cutoff for bad_words list\n",
    "def optimize_model_1():\n",
    "    f1_scores = {}\n",
    "    for i in range(-20, 20):\n",
    "        # All words with a sexism ratio that exceeds the non-sexist comment percentage by at least i / 100 \n",
    "        bad_words = ratio.loc[ratio > 1 - sexist_comment_percent + i / 100].index\n",
    "\n",
    "        predict = []\n",
    "        for comment in clean(X_train):\n",
    "            predict.append(model_1(comment, bad_words))\n",
    "        f1 = f1_score(Y_train, predict, average = \"weighted\") \n",
    "        f1_scores[i] = f1\n",
    "    print(max(f1_scores.items(), key=lambda x:x[1]))\n",
    "    f1_scores = {}\n",
    "    for i in range(-20, 20):\n",
    "        # All words with a sexism ratio that exceeds the non-sexist comment percentage by at least i / 100 \n",
    "        bad_words = ratio.loc[ratio > 1 - sexist_comment_percent + i / 100].index\n",
    "\n",
    "        predict = []\n",
    "        for comment in clean(X_test):\n",
    "            predict.append(model_1(comment, bad_words))\n",
    "        f1 = f1_score(Y_test, predict, average = \"weighted\") \n",
    "        f1_scores[i] = f1\n",
    "    print(max(f1_scores.items(), key=lambda x:x[1]))\n",
    "    print(f1_scores[-8])\n",
    "          \n",
    "optimize_model_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7827b394-47a9-4ccc-8ee3-9a9059064cff",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "1. What preprocessing steps do you follow?\n",
    "   \n",
    "   Your answer:\n",
    "   \n",
    "2. How do you select the features from the inputs?\n",
    "   \n",
    "   Your answer:\n",
    "   \n",
    "3. Which model you use and what is the structure of your model?\n",
    "   \n",
    "   Your answer:\n",
    "   \n",
    "4. How do you train your model?\n",
    "   \n",
    "   Your answer:\n",
    "   \n",
    "5. What is the performance of your best model?\n",
    "   \n",
    "   Your answer:\n",
    "   \n",
    "6. What other models or feature engineering methods would you like to implement in the future?\n",
    "   \n",
    "   Your answer:\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a9a3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
