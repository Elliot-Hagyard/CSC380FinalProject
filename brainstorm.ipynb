{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/elliothagyard/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rewire_id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sexism2022_english-9609</td>\n",
       "      <td>In Nigeria, if you rape a woman, the men rape ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sexism2022_english-16993</td>\n",
       "      <td>Then, she's a keeper. ðŸ˜‰</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sexism2022_english-13149</td>\n",
       "      <td>This is like the Metallica video where the poo...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sexism2022_english-13021</td>\n",
       "      <td>woman?</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sexism2022_english-966</td>\n",
       "      <td>I bet she wished she had a gun</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rewire_id  \\\n",
       "0   sexism2022_english-9609   \n",
       "1  sexism2022_english-16993   \n",
       "2  sexism2022_english-13149   \n",
       "3  sexism2022_english-13021   \n",
       "4    sexism2022_english-966   \n",
       "\n",
       "                                                text  label  split  \n",
       "0  In Nigeria, if you rape a woman, the men rape ...      0  train  \n",
       "1                            Then, she's a keeper. ðŸ˜‰      0  train  \n",
       "2  This is like the Metallica video where the poo...      0  train  \n",
       "3                                             woman?      0  train  \n",
       "4                     I bet she wished she had a gun      0  train  "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "nltk.download(\"wordnet\")\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "comments_df = pd.read_csv('edos_labelled_data.csv') \n",
    "le = preprocessing.LabelEncoder()\n",
    "comments_df[\"label\"] = le.fit_transform(comments_df[\"label\"])\n",
    "comments_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5271    Supporting toxic men and glorifying toxic male...\n",
       "5272    Find a girl with common beliefs. I have. They ...\n",
       "5273    not to mention that she's an outright commie w...\n",
       "5274    Only if you make it clear you're not looking f...\n",
       "5278                      Yea. Most trans women hate men.\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_train_df = comments_df[comments_df[\"split\"] == \"train\"]\n",
    "comments_test_df = comments_df[comments_df[\"split\"] == \"test\"]\n",
    "X_train = comments_train_df[\"text\"]\n",
    "Y_train = comments_train_df[\"label\"]\n",
    "X_test = comments_test_df[\"text\"]\n",
    "Y_test = comments_test_df[\"label\"]\n",
    "X_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(comments: list[str]) -> list[str]:\n",
    "    wln = WordNetLemmatizer()\n",
    "    # remove unicode\n",
    "    # remove punct\n",
    "    comments_clean = [comment.encode(\"ascii\", \"ignore\").decode() for comment in comments]\n",
    "    comments_clean = list(map(lambda x : x.lower(), comments_clean))\n",
    "    comments_clean = [re.sub(r'(#\\w+|\\[user\\]|\\[url\\])', '', comment) for comment in comments_clean]\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    comments_clean = [comment.translate(translator) for comment in comments_clean]\n",
    "    #comments_clean = [[wln.lemmatize(word.strip()) for word in comment.split()] for comment in comments_clean]\n",
    "\n",
    "    return comments_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toWordFreqDF(x, y):\n",
    "    clean_x = clean(x)\n",
    "    vectorizer = CountVectorizer()\n",
    "    vec = vectorizer.fit_transform(clean_x)\n",
    "    frequency_df = pd.DataFrame(vec.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    frequency_df['_label'] = y.tolist()\n",
    "    frequency_df['_label'].tail()\n",
    "    return frequency_df\n",
    "train_freq = toWordFreqDF(X_train, Y_train)\n",
    "test_freq = toWordFreqDF(X_test, Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "sexist_comment_percent = len(Y_train.loc[Y_train== 1]) / len(Y_train) \n",
    "common_freq = train_freq.sum().loc[train_freq.sum() >= 5]\n",
    "sexist = train_freq[train_freq[\"_label\"] == 1].sum().loc[train_freq.sum() >= 5]\n",
    "ratio  = sexist/common_freq.sort_values()\n",
    "bad_words = ratio.loc[ratio > 1 - sexist_comment_percent + .05].index\n",
    "\n",
    "def test_word(sentence : str):\n",
    "    sexist = 0\n",
    "    for word in sentence.split():\n",
    "        if word in bad_words:\n",
    "            sexist = 1\n",
    "            \n",
    "    return sexist\n",
    "\n",
    "predict = []\n",
    "print()\n",
    "for comment in clean(X_test):\n",
    "    predict.append(test_word(comment))\n",
    "print(sum(predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['17', '18', '21', '30', '40', '50', '90', 'abortion', 'above',\n",
      "       'abusive',\n",
      "       ...\n",
      "       'women', 'womens', 'work', 'worse', 'worst', 'yelling', 'yet', 'youd',\n",
      "       'youtube', 'youve'],\n",
      "      dtype='object', length=446)\n",
      "239\n"
     ]
    }
   ],
   "source": [
    "mid_words = ratio.loc[\n",
    "    (1 - sexist_comment_percent + .05 > ratio) \n",
    "    & (ratio > sexist_comment_percent + .1)\n",
    "].index\n",
    "print(mid_words)\n",
    "good_words = ratio.loc[sexist_comment_percent - .05 > ratio].index\n",
    "\n",
    "def test_word2(sentence : str):\n",
    "    sexist = 0\n",
    "    for word in sentence.split():\n",
    "        if word in bad_words:\n",
    "            sexist += 1\n",
    "        elif word in mid_words:\n",
    "            sexist += .2\n",
    "    sexist = 1 if sexist >= 1 else 0\n",
    "    return sexist\n",
    "\n",
    "predict2 = []\n",
    "for comment in clean(X_test):\n",
    "    predict2.append(test_word2(comment))\n",
    "print(sum(predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"numpy.float64\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/elliothagyard/Documents/school/Fall_2023/CS_380/CSC380FinalProject/brainstorm.ipynb Cell 7\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elliothagyard/Documents/school/Fall_2023/CS_380/CSC380FinalProject/brainstorm.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m baseline \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m predict]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elliothagyard/Documents/school/Fall_2023/CS_380/CSC380FinalProject/brainstorm.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m baseline2 \u001b[39m=\u001b[39m [\u001b[39mint\u001b[39m(random\u001b[39m.\u001b[39muniform(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m.8\u001b[39m) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m predict]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/elliothagyard/Documents/school/Fall_2023/CS_380/CSC380FinalProject/brainstorm.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m eval_predictions(baseline)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elliothagyard/Documents/school/Fall_2023/CS_380/CSC380FinalProject/brainstorm.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m eval_predictions(baseline2)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elliothagyard/Documents/school/Fall_2023/CS_380/CSC380FinalProject/brainstorm.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m eval_predictions(predict)\n",
      "\u001b[1;32m/Users/elliothagyard/Documents/school/Fall_2023/CS_380/CSC380FinalProject/brainstorm.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elliothagyard/Documents/school/Fall_2023/CS_380/CSC380FinalProject/brainstorm.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval_predictions\u001b[39m(pred):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/elliothagyard/Documents/school/Fall_2023/CS_380/CSC380FinalProject/brainstorm.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39;49m\u001b[39mrecall: \u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m recall_score(Y_test, pred))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elliothagyard/Documents/school/Fall_2023/CS_380/CSC380FinalProject/brainstorm.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mf1: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m f1_score(Y_test, pred, average\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elliothagyard/Documents/school/Fall_2023/CS_380/CSC380FinalProject/brainstorm.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mprecision: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39mprecision_score(Y_test, pred))\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"numpy.float64\") to str"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, f1_score, recall_score\n",
    "def eval_predictions(pred):\n",
    "    print(\"recall: \" + str(recall_score(Y_test, pred)))\n",
    "    print(\"f1: \" + str(f1_score(Y_test, pred, average=\"weighted\")))\n",
    "    print(\"precision: \" + str(precision_score(Y_test, pred)))\n",
    "import random\n",
    "baseline = [0 for i in predict]\n",
    "baseline2 = [int(random.uniform(0, 1) > .8) for i in predict]\n",
    "eval_predictions(baseline)\n",
    "eval_predictions(baseline2)\n",
    "eval_predictions(predict)\n",
    "eval_predictions(predict2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
